# ìˆ˜ëŠ¥ ë¬¸ì œ í’€ì´ ëª¨ë¸

![ë©”ì¸ ì •ì  í™”ë©´.png](/assets/banner.png)

í•œêµ­ì–´ì˜ íŠ¹ì„±ê³¼ ìˆ˜ëŠ¥ ì‹œí—˜ì˜ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ **ìˆ˜ëŠ¥ì— ìµœì í™”ëœ ëª¨ë¸**ì„ ë§Œë“­ë‹ˆë‹¤.

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©í‘œ**: ìˆ˜ëŠ¥ ë¬¸ì œ í’€ì´ë¥¼ ìœ„í•œ ìµœì í™”ëœ ì–¸ì–´ ëª¨ë¸ ì—°êµ¬ ë° ê°œë°œ
- **ì£¼ìš” ë‚´ìš©**:
  - ë‹¤ì–‘í•œ ëª¨ë¸ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„±ëŠ¥ ë¹„êµ
  - ë°ì´í„° ì •ì œ ë° ì¦ê°•ì„ í†µí•œ í•™ìŠµ íš¨ìœ¨ í–¥ìƒ
  - CoT(Chain of Thought) ë°©ì‹ ì ìš©ì— ë”°ë¥¸ ì¶”ë¡  ëŠ¥ë ¥ í‰ê°€
  - RAG(Retrieval-Augmented Generation) í™œìš©ìœ¼ë¡œ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€ ì„±ëŠ¥ ì‹¤í—˜

## ìµœì¢… ê²°ê³¼

`4bit` ì–‘ìí™”ë¥¼ ì ìš©í•œ `Qwen2.5-32B-Instruct` ëª¨ë¸ì„ í™œìš©í•˜ì—¬ **0.7747ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±**í–ˆìŠµë‹ˆë‹¤.

| ëª¨ë¸                                | ì¡°ê±´                                    | Accuracy   |
| ----------------------------------- | --------------------------------------- | ---------- |
| finetuned gemma-2b-ko (base)        | ê¸°ë³¸ ì„¤ì •                               | 0.3862     |
| finetuned gemma-2b-ko               | ë°ì´í„° ì •ì œ ë° ì¦ê°•                     | 0.4138     |
| finetuned Qwen-2.5-32b-Instruct     | ê¸°ë³¸ ì„¤ì •                               | 0.7540     |
| finetuned Qwen-2.5-32b-Instruct     | ë°ì´í„° ì •ì œ ë° ì¦ê°•                     | 0.7632     |
| **finetuned Qwen-2.5-32b-Instruct** | **ë°ì´í„° ì •ì œ ë° ì¦ê°• + Prompt Tuning** | **0.7747** |

ìœ„ í‘œëŠ” ìˆ˜ëŠ¥í˜• ë¬¸ì œ í’€ì´ ì„±ëŠ¥ì„ ëª¨ë¸ê³¼ ì‹¤í—˜ ì¡°ê±´ì— ë”°ë¼ ë¹„êµí•œ ê²°ê³¼ì…ë‹ˆë‹¤.

ë² ì´ìŠ¤ ëª¨ë¸ì¸ `gemma-2b-ko`ì—ì„œ ë°ì´í„° ì •ì œ ë° ì¦ê°•ìœ¼ë¡œ ì†Œí­ ì„±ëŠ¥ í–¥ìƒì„ í™•ì¸í•˜ì˜€ìœ¼ë©°, ì´ëŠ” ìµœì¢… ì„ ì •ëœ ëª¨ë¸ì¸ `Qwen-2.5-32b-Instruct`ì—ì„œë„ í™•ì¸ í• ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ ë°ì´í„° ì¦ê°• ë° Prompt Tuningì„ ì¶”ê°€í•œ **Qwen-2.5-32b-Instruct** ëª¨ë¸ì´ **0.7747**ë¡œ ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ë‹¤ì–‘í•œ ëª¨ë¸ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„±ëŠ¥ ë¹„êµ

ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ëŠ¥ ë¬¸ì œ í’€ì´ ì„±ëŠ¥ì„ í‰ê°€í•˜ì˜€ìŠµë‹ˆë‹¤. ì£¼ìš” ì‹¤í—˜ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:

### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ

ì—¬ëŸ¬ ì–¸ì–´ ëª¨ë¸(gemma, Qwen, Llama, SOLAR, EXAONE ë“±)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ ê²°ê³¼ì…ë‹ˆë‹¤:

![model compare](assets/model-compare.png)

- `Qwen-2.5-32b-Instruct` ëª¨ë¸ì´ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ì˜€ìŠµë‹ˆë‹¤.
- ë¹„ìŠ·í•œ íŒŒë¼ë¯¸í„° í¬ê¸° ë‚´ì—ì—ì„œ `Qwen` ê³„ì—´ì˜ ëª¨ë¸ì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

### Qwen ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° í¬ê¸°ë³„ ì„±ëŠ¥ ë¹„êµ

`Qwen` ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° í¬ê¸°(3B, 7B, 14B, 32B)ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ì…ë‹ˆë‹¤:

![qwen_parameter compare](assets/qwen-parameter-compare.png)

- 14Bê³¼ 32Bì˜ ê²½ìš° 4bit ì–‘ìí™”ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
- ì–‘ìí™”ë¥¼ ì ìš©í•¨í–ˆìŒì—ë„ íŒŒë¼ë¯¸í„° í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

### í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ë³„ ì„±ëŠ¥ ë¹„êµ

í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” `LORA r`, `LORA alpha` ì¡°í•©ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ í‰ê°€í•˜ì˜€ìŠµë‹ˆë‹¤:

![hyperparameter compare](assets/hyperparameter-compare.png)

- Mid ACCì™€ Final ACC ëª¨ë‘ì—ì„œ `r: 8, alpha: 16` ì„¤ì •ì´ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ì˜€ìŠµë‹ˆë‹¤.

## ë°ì´í„° ì •ì œ ë° ì¦ê°•

### ë°ì´í„° ì •ì œ

ì „ì²´ í•™ìŠµ ë°ì´í„° 2031ê°œì—ì„œ ë¬¸ì œ ì˜¤ë¥˜ 4ê°œë¥¼ ì‚­ì œí•˜ê³  ì˜ëª»ëœ ì •ë‹µ 6ê°œë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì§€ë¬¸ì— ë³´ê¸°ê°€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ë³´ê¸° ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬í•˜ì˜€ìœ¼ë©°, í•™ìŠµì— ë°©í•´ë˜ëŠ” ê¸°ì‚¬ ë°ì´í„°ì˜ ê¸°ì ì´ë¦„ ë° ì—°ë½ì²˜ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.

### ë°ì´í„° ì¦ê°•

#### ì™¸ì  ì¶”ë¡  ë¬¸ì œì— ëŒ€í•œ ì¬êµ¬ì„± ë° ì¦ê°•

![augmentation pipeline](/assets/augmentation-pipeline.png)

ì™¸ë¶€ ì§€ì‹ì´ í•„ìš”í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê¸°ì¡´ ì§€ë¬¸ì— ë°ì´í„°ë¥¼ ë³´ê°•í•˜ì—¬ ë°ì´í„°ë¥¼ ì¦ê°•í•˜ëŠ” ë°©ë²•ì„ ì‹œë„í–ˆìŠµë‹ˆë‹¤.

1. **í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ**: ë¬¸ì œ í•´ê²°ì— í•„ìš”í•œ ì£¼ìš” ì •ë³´ë¥¼ ë„ì¶œ
2. **ê´€ë ¨ ì§€ë¬¸ í™•ë³´**: ì¶”ì¶œëœ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ í¬ë¡¤ë§
3. **ì§€ë¬¸ ë³´ê°•**: í™•ë³´ëœ ë¬¸ì„œë¥¼ ì§€ë¬¸ì— ì¶”ê°€í•˜ê³ , ëª¨ë¸ ì…ë ¥ ê¸¸ì´ì— ë§ì¶° ìš”ì•½ëœ ë¬¸ì„œë¥¼ í™œìš©

ê·¸ëŸ¬ë‚˜ ëª¨ë¸ í•™ìŠµ ê²°ê³¼, ì„±ëŠ¥ í–¥ìƒì—ëŠ” ì‹¤íŒ¨í–ˆìœ¼ë©° ì´ëŠ” ì¼ë¶€ ìˆ˜ëŠ¥í˜• ë¬¸ì œì¡°ì°¨ ì™¸ë¶€ ì§€ì‹ì— í¬ê²Œ ì˜ì¡´í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

ì´ ë°œê²¬ì„ ë°”íƒ•ìœ¼ë¡œ, RAG(ì •ë³´ ê²€ìƒ‰ ê¸°ë°˜ ìƒì„±) ì ‘ê·¼ë²•ì„ ë„ì…í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤.

#### ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ í†µí•œ ë°ì´í„° ì¦ê°•

KMMLU ë²¤ì¹˜ë§ˆí¬ ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰ëœ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµ ë°ì´í„°ì— ì í•©í•œ ë°ì´í„°ë¥¼ ì„ ì •í•˜ì˜€ìŠµë‹ˆë‹¤.

![kmmlu-dataset](/assets/kmmlu-dataset.png)

- **KorNLI & KorSTS, KoBBQ ë“±**: ë‹¤ì§€ì„ ë‹¤í˜• ë¬¸ì œë¡œ ë³€í™˜í•˜ê¸° ì–´ë ¤ì›€
- **HAE-RAE Bench.**: ë‹¤ì§€ì„ ë‹¤í˜•ìœ¼ë¡œ ê°€ê³µì´ ìš©ì´í•˜ê³ , í•™ìŠµ ëª©í‘œì™€ ë†’ì€ ì—°ê´€ì„±ì„ ê°€ì§

ë¶„ì„ ê²°ê³¼, **HAE-RAE Bench. ë°ì´í„°ì…‹ì´ ê°€ì¥ ì í•©í•œ ì„ íƒ**ìœ¼ë¡œ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **ë…í•´ ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„°ëŠ” Test ë°ì´í„°ì™€ ë†’ì€ ì—°ê´€ì„±ì„ ë³´ì—¬** ì„±ëŠ¥ ê°œì„ ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤.

ì´ë¥¼ í†µí•´ ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ì¦ê°•í•˜ëŠ” ê²ƒë³´ë‹¤, **ë°ì´í„°ì˜ í’ˆì§ˆê³¼ Taskì™€ì˜ ì—°ê´€ì„±**ì´ ì„±ëŠ¥ì— í•µì‹¬ì ì¸ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

> ë” ìì„¸í•œ ë°ì´í„° ì¦ê°• ì‹¤í—˜ ë‚´ìš©ì€ [ì—¬ê¸°](https://gamchan.notion.site/146815b39d39807884f1f785c2829da6?v=086629b8bb6f49a5a1b54a0ec44d6630&pvs=4)ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

## Prompt Tuning

## CoT ì ìš©ì— ë”°ë¥¸ ì¶”ë¡  ëŠ¥ë ¥ í‰ê°€

`google/gemma-2-2b-it`ì™€ `Qwen/Qwen-2.5-7B-Instruct`ì— ëŒ€í•´ **Chain of Thought(CoT)** ë°©ì‹ì˜ ì„±ëŠ¥ì„ ë¹„êµ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ì€ ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤:

1. **ì •ë‹µ ë²ˆí˜¸**(ìˆ«ì)ë§Œ ìƒì„±
2. **JSON í˜•ì‹ìœ¼ë¡œ reasoningê³¼ ì •ë‹µ**ì„ í¬í•¨í•˜ì—¬ ìƒì„± (CoT ë°©ì‹)

| **ëª¨ë¸**             | **ì‹¤í—˜ ì„¤ì •**            | **ì‚¬ì „ í•™ìŠµ ëª¨ë¸** | **íŒŒì¸íŠœë‹ ëª¨ë¸** |
| -------------------- | ------------------------ | ------------------ | ----------------- |
| gemma-2b-it          | ì •ë‹µ ë²ˆí˜¸ë§Œ ìƒì„±         | 0.5034             | **0.5264**        |
| gemma-2b-it          | CoT ì‘ë‹µ ìƒì„±(JSON í˜•ì‹) | 0.4885             | 0.4437            |
| Qwen-2.5-7B-Instruct | ì •ë‹µ ë²ˆí˜¸ë§Œ ìƒì„±         | 0.6092             | **0.6207**        |
| Qwen-2.5-7B-Instruct | CoT ì‘ë‹µ ìƒì„±(JSON í˜•ì‹) | 0.5609             | 0.6092            |

- **ì •ë‹µ ë²ˆí˜¸ë§Œ ìƒì„±**í•˜ëŠ” ë°©ì‹ì´ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë” ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
- **CoT ë°©ì‹**ì€ `finetuning` ì‹œ `Qwen 7B` ëª¨ë¸ì—ì„œ ì¼ë¶€ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ì§€ë§Œ, `gemma 2b` ëª¨ë¸ì—ì„œëŠ” ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤.

### ë¶„ì„

- **ëª¨ë¸ í¬ê¸° í•œê³„**: CoT ë°©ì‹ì€ ë” ë§ì€ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ìš”êµ¬í•˜ë©°, ì‘ì€ ëª¨ë¸ì—ì„œëŠ” ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ë°ì´í„° íŠ¹ì„±**: í”„ë¡œì íŠ¸ì˜ ì£¼ìš” Taskê°€ êµ­ì–´ ë° ì‚¬íšŒ ê³¼ëª© ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´, CoT ë°©ì‹ì´ ìš”êµ¬í•˜ëŠ” ë‹¨ê³„ì  ì¶”ë¡ ì´ ì¶©ë¶„íˆ í™œìš©ë˜ì§€ ëª»í–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.

> `config.yaml`ì—ì„œ `common.cot_on=True` ì„¤ì • í›„ `langcahin_inference.py` ì‹¤í–‰í•¨ìœ¼ë¡œì¨ CoTë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## RAGë¥¼ í™œìš©í•œ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€ ì„±ëŠ¥ ì‹¤í—˜

## Streamlit

![streamlit demo](assets/streamlit-demo.png)

## Project Quick Setup

### Requirements

- Python: 3.10
- CUDA: >= 12.1
- PyTorch: 2.5.1+cu121

### Git Clone

```shell
$ git clone git@github.com:boostcampaitech7/level2-nlp-generationfornlp-nlp-06-lv3.git
$ cd level2-nlp-generationfornlp-nlp-06-lv3
```

### Import Data

`data/` ë””ë ‰í† ë¦¬ì•ˆì— `train/valid/test` ë°ì´í„°ë¥¼ ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.

### Create Virtual Environment

```shell
$ python -m venv .venv
$ source .venv/bin/activate
(.venv) $
```

### Install Packages

```shell
(.venv) $ pip install -r requirements.txt
```

### Setup Envronment Variables

`.env`ë¥¼ ìƒì„± í›„ í™˜ê²½ ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.

```shell
(.venv) $ cp .env.example .env
```

- `HF_TOKEN`: `HuggingFace`ë¡œ ë¶€í„° ëª¨ë¸ì„ ë‚´ë ¤ë°›ê¸° ìœ„í•´ í•„ìš”í•œ í† í°
- `STREAMLIT_DATA_PATH`: streamlit êµ¬ë™ ì‹œ í•„ìš”í•œ ê¸°ë³¸ ì„¤ì • ë°ì´í„° ê²½ë¡œ
- `STREAMLIT_EXPERIMENT_DATA_PATH`: streamlit êµ¬ë™ ì‹œ í•„ìš”í•œ ì‹¤í—˜ ë°ì´í„° ê²½ë¡œ
- `PINECONE_API_KEY`: RAG vector db pinecone api key
- `PINECONE_INDEX`: RAG vector db pinecone index
- `PINECONE_ENVIRONMENT`: RAG vector db pinecone Environment
- `OPENAI_API_KEY`: ë°ì´í„° ì¦ê°•ìš© api key

```shell
HF_TOKEN={your_hf_token}
STREAMLIT_DATA_PATH={streamlit_data_path}
STREAMLIT_EXPERIMENT_DATA_PATH={streamlit_experiment_data_path}

# API Key for Pinecone service
PINECONE_API_KEY={your_api_key}
# Index name used in Pinecone
PINECONE_INDEX={your_index_name}
# Environment for Pinecone (e.g., 'us-west1-gcp')
PINECONE_ENVIRONMENT={your_environment}

OPENAI_API_KEY={your_openai_api_key}
```

## Config.yaml

`config.yaml` íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” í™˜ê²½ì—ì„œ ì‹¤í–‰ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ê¸°ë³¸ ì„¤ì • ì˜ˆì‹œì…ë‹ˆë‹¤:

```yaml
model:
  name_or_path: "unsloth/Qwen2.5-3B-Instruct-bnb-4bit"
  response_template: "<|im_start|>assistant\n"
  without_system_role: false # Deprecated (í•­ìƒ system ì—†ì´ ë™ì‘)
  torch_dtype: "float16" # float32, float16, bfloat16 / ëª¨ë¸ì˜ ê¸°ë³¸ ë°ì´í„° íƒ€ì…

common:
  seed: 42
  device: "cuda"
  cot_on: false # cot ì‚¬ìš© ì‹œ prompt_templateì„ cot_jsonìœ¼ë¡œ ë³€ê²½ í•„ìš”
  prompt_template: "base" # base, cot_json

bnb:
  load_in_8bit: false
  load_in_4bit: false
  bnb_4bit_compute_dtype: "float16" # float16, float32, bfloat16 / 4 bit ì–‘ìí™” ë°ì´í„°ì˜ ê³„ì‚° ë°ì´í„° íƒ€ì…
  bnb_4bit_use_double_quant: false # true ì‹œ ë”ë¸” ì–‘ìí™”(ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ, ì‹œê°„ ë” ê±¸ë¦¼)
  bnb_4bit_quant_type: "nf4" # nf4, fp4

earlystop:
  metric_for_best_model: "eval_loss" # ëª¨ë‹ˆí„°ë§í•  ì§€í‘œ ì´ë¦„
  early_stopping_patience: 1 # ê°œì„ ë˜ì§€ ì•ŠëŠ” ì—í­ ìˆ˜
  early_stopping_threshold: 0.0 # ê°œì„ ìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ ë³€í™”ëŸ‰
  greater_is_better: false # ì§€í‘œê°€ ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ê²½ìš° True

peft:
  r: 6
  lora_alpha: 8
  lora_dropout: 0.05
  target_modules: ["q_proj", "k_proj"]
  bias: "none"
  task_type: "CAUSAL_LM"

sft:
  do_train: true
  do_eval: true
  lr_scheduler_type: "cosine"
  max_seq_length: 1024
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  num_train_epochs: 3
  learning_rate: 2.0e-5 # ì§€ìˆ˜ ìë¦¿ìˆ˜ ì•ë¶€ë¶„ì„ ì‹¤ìˆ˜ í˜•íƒœë¡œ ì‘ì„± ('2'-> x, '2.0'-> o)
  weight_decay: 0.01
  logging_strategy: "steps" # epoch or steps, epochì˜ ê²½ìš° logging_steps ë¬´ì‹œ
  logging_steps: 100
  save_strategy: "epoch"
  eval_strategy: "epoch"
  load_best_model_at_end: true
  save_total_limit: 1
  save_only_model: true
  report_to: "wandb" # none or wandb, wandbë¡œ ë³€ê²½í•˜ì—¬ ë¡œê·¸ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
  gradient_checkpointing: false
  gradient_accumulation_steps: 4

wandb:
  project: "MMLU"

train:
  data_path: "data/train_v2.0.1.csv" # wandb ë¡œê¹… ì‚¬ìš©ì‹œ íŒŒì¼ëª… ë³€ê²… ê¸ˆì§€(ë°ì´í„° ë²„ì „ ì •ë³´ ì‚¬ìš©)
  valid_data_path: "data/valid_v2.0.1.csv"
  valid_output_path: "data/valid_output.csv"

inference:
  model_path: "outputs/Qwen2.5-3B-Instruct-bnb-4bit" # í•™ìŠµëœ ëª¨ë¸ë¡œ ë³€ê²½ í•„ìš”
  data_path: "data/test_v1.0.2.csv"
  output_path: "data/output.csv"
  raw_output_path: "data/raw_output.csv"
  default_answer: 1
```

### Custom Config

ê¸°ë³¸ ì„¤ì • ì™¸ì— ì‚¬ìš©ì ì •ì˜ ì„¤ì •ì„ ì‚¬ìš©í•˜ë ¤ë©´ `configs/config.yaml` íŒŒì¼ì„ ë³µì‚¬í•œ ë’¤ ìˆ˜ì •í•˜ì„¸ìš”:

```shell
(.venv) $ cp configs/config.yaml configs/config_custom.yaml
(.venv) $ vi configs/config_custom.yaml
```

## Train ë° Inference ì‹¤í–‰

### Train

í•™ìŠµì„ ì‹¤í–‰í•˜ë ¤ë©´ ê¸°ë³¸ `train.py` íŒŒì¼ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:

```shell
(.venv) $ python train.py
```

ì»¤ìŠ¤í…€ ì„¤ì •ì„ ì ìš©í•˜ë ¤ë©´ -c ë˜ëŠ” --config ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”:

```shell
(.venv) $ python train.py -c config_custom.yaml
```

- -c ì˜µì…˜ì—ëŠ” configs ë””ë ‰í† ë¦¬ ë‚´ë¶€ì˜ YAML íŒŒì¼ ì´ë¦„ë§Œ ì…ë ¥í•©ë‹ˆë‹¤.

### Inference

í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤:

```shell
(.venv) $ python inference.py
```

ì»¤ìŠ¤í…€ ì„¤ì •ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:

```
(.venv) $ python inference.py -c config_custom.yaml
```

`valid` ë°ì´í„°ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ë ¤ë©´ `-v` ì˜µì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

> `valid`ì— ëŒ€í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

```shell
(.venv) $ python inference.py -v

# or

(.venv) $ python inference.py -c config_custom.yaml -v
```

## Contribution Guide

í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì—… ì‹œ ì¼ê´€ì„±ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.

### ì»¤ë°‹ í…œí”Œë¦¿ ì‚¬ìš©ë²•

í”„ë¡œì íŠ¸ì—ì„œ ì»¤ë°‹ ë©”ì‹œì§€ í˜•ì‹ì„ í†µì¼í•˜ê¸° ìœ„í•´ ì»¤ë°‹ í…œí”Œë¦¿ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ í…œí”Œë¦¿ì„ ì ìš©í•˜ì„¸ìš”:

```
$ git config commit.template .gitcommit_template
```

- `.gitcommit_template` íŒŒì¼ì€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ” ì»¤ë°‹ í…œí”Œë¦¿ íŒŒì¼ì…ë‹ˆë‹¤.
- ìœ„ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ì»¤ë°‹ ì‹œ í…œí”Œë¦¿ì´ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì§‘ë‹ˆë‹¤.

## Collaborators

|          [ê°•ê°ì°¬](https://github.com/gsgh3016)          |          [ë‹¨ì´ì—´](https://github.com/eyeol)          |          [ì•ˆí˜œì¤€](https://github.com/jagaldol)          |          [ìœ ì„ ìš°](https://github.com/Usunwoo)          |          [ìœ ì±„ì€](https://github.com/canolayoo78)          |          [ì´ì±„í˜¸](https://github.com/chell9999)          |
| :-----------------------------------------------------: | :--------------------------------------------------: | :-----------------------------------------------------: | :----------------------------------------------------: | :--------------------------------------------------------: | :------------------------------------------------------: |
| <img src="https://github.com/gsgh3016.png" width="100"> | <img src="https://github.com/eyeol.png" width="100"> | <img src="https://github.com/jagaldol.png" width="100"> | <img src="https://github.com/Usunwoo.png" width="100"> | <img src="https://github.com/canolayoo78.png" width="100"> | <img src="https://github.com/chell9999.png" width="100"> |
